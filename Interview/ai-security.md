# AI Security Interview Questions

## üéØ AI Security Fundamentals

**Q: What are AI security threats?**
A: Prompt injection, model poisoning, data leakage, adversarial attacks, privacy violations, model theft.

**Q: Explain prompt injection**
A: Attack where malicious input manipulates LLM behavior, bypassing safety filters or extracting information.

**Q: How do you defend against prompt injection?**
A: Input sanitization, system prompt hardening, output validation, guardrails, monitoring.

## üîí Security Practices

**Q: Explain model poisoning**
A: Attack compromising model during training or through malicious updates, inserting backdoors or manipulating behavior.

**Q: How do you secure ML pipelines?**
A: Secure data access, isolate training, sign models, monitor pipelines, implement access controls, audit logging.

**Q: What are guardrails?**
A: Safety mechanisms enforcing security, compliance, and behavior in AI systems through input/output validation.

## üìù Scenario Questions

**Q: Design secure LLM application**
A: Input validation, prompt injection defense, output filtering, guardrails, monitoring, rate limiting, access controls.

**Q: How do you monitor AI models?**
A: Track predictions, detect drift, monitor performance, detect anomalies, track security events, compliance monitoring.

## ‚úÖ Key Areas

- LLM security
- Model security
- Pipeline security
- Threat detection
- Guardrails
- Monitoring

---

**Next**: Review AIOps interview questions.

